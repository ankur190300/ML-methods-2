{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2250, 2) (2250, 1)\n",
      "      label\n",
      "0         0\n",
      "1         0\n",
      "2         1\n",
      "3         0\n",
      "4         1\n",
      "5         0\n",
      "6         0\n",
      "7         0\n",
      "8         0\n",
      "9         1\n",
      "10        0\n",
      "11        1\n",
      "12        1\n",
      "13        0\n",
      "14        1\n",
      "15        0\n",
      "16        1\n",
      "17        0\n",
      "18        1\n",
      "19        1\n",
      "20        1\n",
      "21        0\n",
      "22        0\n",
      "23        1\n",
      "24        0\n",
      "25        1\n",
      "26        0\n",
      "27        0\n",
      "28        0\n",
      "29        1\n",
      "...     ...\n",
      "2220      0\n",
      "2221      0\n",
      "2222      1\n",
      "2223      1\n",
      "2224      1\n",
      "2225      0\n",
      "2226      1\n",
      "2227      0\n",
      "2228      1\n",
      "2229      0\n",
      "2230      1\n",
      "2231      1\n",
      "2232      1\n",
      "2233      1\n",
      "2234      1\n",
      "2235      1\n",
      "2236      0\n",
      "2237      1\n",
      "2238      0\n",
      "2239      0\n",
      "2240      0\n",
      "2241      0\n",
      "2242      1\n",
      "2243      0\n",
      "2244      0\n",
      "2245      1\n",
      "2246      1\n",
      "2247      1\n",
      "2248      1\n",
      "2249      0\n",
      "\n",
      "[2250 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "X= pd.read_csv(\"./datasets/NeuralNetwork1_X_Train.csv\")\n",
    "Y = pd.read_csv(\"./datasets/NeuralNetwork1_Y_Train.csv\")\n",
    "print(X.shape, Y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making the Neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "from keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 2)                 6         \n",
      "=================================================================\n",
      "Total params: 6\n",
      "Trainable params: 6\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# defining the model\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(Dense(2, activation='sigmoid', input_shape=(2,)))\n",
    "#model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "#compiling the model\n",
    "model.compile(optimizer= 'adam', metrics=[\"accuracy\"], loss= \"binary_crossentropy\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1800 samples, validate on 450 samples\n",
      "Epoch 1/100\n",
      "1800/1800 [==============================] - 0s 194us/step - loss: 0.7859 - accuracy: 0.4422 - val_loss: 0.7670 - val_accuracy: 0.4678\n",
      "Epoch 2/100\n",
      "1800/1800 [==============================] - 0s 98us/step - loss: 0.7608 - accuracy: 0.4578 - val_loss: 0.7434 - val_accuracy: 0.4733\n",
      "Epoch 3/100\n",
      "1800/1800 [==============================] - 0s 97us/step - loss: 0.7376 - accuracy: 0.4750 - val_loss: 0.7212 - val_accuracy: 0.4944\n",
      "Epoch 4/100\n",
      "1800/1800 [==============================] - 0s 88us/step - loss: 0.7158 - accuracy: 0.4914 - val_loss: 0.7006 - val_accuracy: 0.5044\n",
      "Epoch 5/100\n",
      "1800/1800 [==============================] - 0s 101us/step - loss: 0.6955 - accuracy: 0.5042 - val_loss: 0.6810 - val_accuracy: 0.5156\n",
      "Epoch 6/100\n",
      "1800/1800 [==============================] - 0s 86us/step - loss: 0.6764 - accuracy: 0.5206 - val_loss: 0.6630 - val_accuracy: 0.5278\n",
      "Epoch 7/100\n",
      "1800/1800 [==============================] - 0s 77us/step - loss: 0.6584 - accuracy: 0.5381 - val_loss: 0.6461 - val_accuracy: 0.5433\n",
      "Epoch 8/100\n",
      "1800/1800 [==============================] - 0s 71us/step - loss: 0.6418 - accuracy: 0.5556 - val_loss: 0.6301 - val_accuracy: 0.5578\n",
      "Epoch 9/100\n",
      "1800/1800 [==============================] - 0s 76us/step - loss: 0.6264 - accuracy: 0.5733 - val_loss: 0.6151 - val_accuracy: 0.5789\n",
      "Epoch 10/100\n",
      "1800/1800 [==============================] - 0s 92us/step - loss: 0.6118 - accuracy: 0.5894 - val_loss: 0.6015 - val_accuracy: 0.6000\n",
      "Epoch 11/100\n",
      "1800/1800 [==============================] - 0s 78us/step - loss: 0.5982 - accuracy: 0.6039 - val_loss: 0.5880 - val_accuracy: 0.6144\n",
      "Epoch 12/100\n",
      "1800/1800 [==============================] - 0s 89us/step - loss: 0.5854 - accuracy: 0.6133 - val_loss: 0.5758 - val_accuracy: 0.6300\n",
      "Epoch 13/100\n",
      "1800/1800 [==============================] - 0s 76us/step - loss: 0.5735 - accuracy: 0.6233 - val_loss: 0.5645 - val_accuracy: 0.6411\n",
      "Epoch 14/100\n",
      "1800/1800 [==============================] - 0s 78us/step - loss: 0.5624 - accuracy: 0.6381 - val_loss: 0.5536 - val_accuracy: 0.6500\n",
      "Epoch 15/100\n",
      "1800/1800 [==============================] - 0s 77us/step - loss: 0.5518 - accuracy: 0.6489 - val_loss: 0.5435 - val_accuracy: 0.6589\n",
      "Epoch 16/100\n",
      "1800/1800 [==============================] - 0s 78us/step - loss: 0.5420 - accuracy: 0.6592 - val_loss: 0.5337 - val_accuracy: 0.6778\n",
      "Epoch 17/100\n",
      "1800/1800 [==============================] - 0s 92us/step - loss: 0.5327 - accuracy: 0.6694 - val_loss: 0.5248 - val_accuracy: 0.6878\n",
      "Epoch 18/100\n",
      "1800/1800 [==============================] - 0s 89us/step - loss: 0.5239 - accuracy: 0.6822 - val_loss: 0.5160 - val_accuracy: 0.6922\n",
      "Epoch 19/100\n",
      "1800/1800 [==============================] - 0s 118us/step - loss: 0.5156 - accuracy: 0.6906 - val_loss: 0.5080 - val_accuracy: 0.7000\n",
      "Epoch 20/100\n",
      "1800/1800 [==============================] - 0s 92us/step - loss: 0.5078 - accuracy: 0.7003 - val_loss: 0.5003 - val_accuracy: 0.7033\n",
      "Epoch 21/100\n",
      "1800/1800 [==============================] - 0s 85us/step - loss: 0.5005 - accuracy: 0.7064 - val_loss: 0.4930 - val_accuracy: 0.7156\n",
      "Epoch 22/100\n",
      "1800/1800 [==============================] - 0s 89us/step - loss: 0.4936 - accuracy: 0.7114 - val_loss: 0.4862 - val_accuracy: 0.7189\n",
      "Epoch 23/100\n",
      "1800/1800 [==============================] - 0s 103us/step - loss: 0.4870 - accuracy: 0.7200 - val_loss: 0.4797 - val_accuracy: 0.7278\n",
      "Epoch 24/100\n",
      "1800/1800 [==============================] - 0s 92us/step - loss: 0.4808 - accuracy: 0.7264 - val_loss: 0.4734 - val_accuracy: 0.7333\n",
      "Epoch 25/100\n",
      "1800/1800 [==============================] - 0s 93us/step - loss: 0.4749 - accuracy: 0.7344 - val_loss: 0.4675 - val_accuracy: 0.7400\n",
      "Epoch 26/100\n",
      "1800/1800 [==============================] - 0s 95us/step - loss: 0.4691 - accuracy: 0.7400 - val_loss: 0.4618 - val_accuracy: 0.7478\n",
      "Epoch 27/100\n",
      "1800/1800 [==============================] - 0s 90us/step - loss: 0.4638 - accuracy: 0.7439 - val_loss: 0.4564 - val_accuracy: 0.7511\n",
      "Epoch 28/100\n",
      "1800/1800 [==============================] - 0s 92us/step - loss: 0.4587 - accuracy: 0.7464 - val_loss: 0.4510 - val_accuracy: 0.7533\n",
      "Epoch 29/100\n",
      "1800/1800 [==============================] - 0s 88us/step - loss: 0.4537 - accuracy: 0.7497 - val_loss: 0.4462 - val_accuracy: 0.7611\n",
      "Epoch 30/100\n",
      "1800/1800 [==============================] - 0s 80us/step - loss: 0.4490 - accuracy: 0.7539 - val_loss: 0.4416 - val_accuracy: 0.7633\n",
      "Epoch 31/100\n",
      "1800/1800 [==============================] - 0s 75us/step - loss: 0.4446 - accuracy: 0.7597 - val_loss: 0.4369 - val_accuracy: 0.7656\n",
      "Epoch 32/100\n",
      "1800/1800 [==============================] - 0s 83us/step - loss: 0.4402 - accuracy: 0.7619 - val_loss: 0.4324 - val_accuracy: 0.7689\n",
      "Epoch 33/100\n",
      "1800/1800 [==============================] - 0s 95us/step - loss: 0.4360 - accuracy: 0.7647 - val_loss: 0.4282 - val_accuracy: 0.7711\n",
      "Epoch 34/100\n",
      "1800/1800 [==============================] - 0s 88us/step - loss: 0.4320 - accuracy: 0.7675 - val_loss: 0.4243 - val_accuracy: 0.7722\n",
      "Epoch 35/100\n",
      "1800/1800 [==============================] - 0s 79us/step - loss: 0.4282 - accuracy: 0.7700 - val_loss: 0.4201 - val_accuracy: 0.7756\n",
      "Epoch 36/100\n",
      "1800/1800 [==============================] - 0s 88us/step - loss: 0.4245 - accuracy: 0.7725 - val_loss: 0.4164 - val_accuracy: 0.7811\n",
      "Epoch 37/100\n",
      "1800/1800 [==============================] - 0s 100us/step - loss: 0.4209 - accuracy: 0.7753 - val_loss: 0.4127 - val_accuracy: 0.7856\n",
      "Epoch 38/100\n",
      "1800/1800 [==============================] - 0s 88us/step - loss: 0.4175 - accuracy: 0.7769 - val_loss: 0.4093 - val_accuracy: 0.7878\n",
      "Epoch 39/100\n",
      "1800/1800 [==============================] - 0s 92us/step - loss: 0.4142 - accuracy: 0.7792 - val_loss: 0.4059 - val_accuracy: 0.7889\n",
      "Epoch 40/100\n",
      "1800/1800 [==============================] - 0s 92us/step - loss: 0.4110 - accuracy: 0.7825 - val_loss: 0.4026 - val_accuracy: 0.7922\n",
      "Epoch 41/100\n",
      "1800/1800 [==============================] - 0s 88us/step - loss: 0.4079 - accuracy: 0.7856 - val_loss: 0.3994 - val_accuracy: 0.7944\n",
      "Epoch 42/100\n",
      "1800/1800 [==============================] - 0s 109us/step - loss: 0.4048 - accuracy: 0.7869 - val_loss: 0.3959 - val_accuracy: 0.7989\n",
      "Epoch 43/100\n",
      "1800/1800 [==============================] - 0s 91us/step - loss: 0.4019 - accuracy: 0.7908 - val_loss: 0.3928 - val_accuracy: 0.8022\n",
      "Epoch 44/100\n",
      "1800/1800 [==============================] - 0s 81us/step - loss: 0.3991 - accuracy: 0.7922 - val_loss: 0.3898 - val_accuracy: 0.8044\n",
      "Epoch 45/100\n",
      "1800/1800 [==============================] - 0s 88us/step - loss: 0.3963 - accuracy: 0.7944 - val_loss: 0.3870 - val_accuracy: 0.8056\n",
      "Epoch 46/100\n",
      "1800/1800 [==============================] - 0s 105us/step - loss: 0.3937 - accuracy: 0.7983 - val_loss: 0.3841 - val_accuracy: 0.8078\n",
      "Epoch 47/100\n",
      "1800/1800 [==============================] - 0s 88us/step - loss: 0.3910 - accuracy: 0.8006 - val_loss: 0.3812 - val_accuracy: 0.8089\n",
      "Epoch 48/100\n",
      "1800/1800 [==============================] - 0s 100us/step - loss: 0.3885 - accuracy: 0.8022 - val_loss: 0.3784 - val_accuracy: 0.8122\n",
      "Epoch 49/100\n",
      "1800/1800 [==============================] - 0s 85us/step - loss: 0.3860 - accuracy: 0.8042 - val_loss: 0.3758 - val_accuracy: 0.8133\n",
      "Epoch 50/100\n",
      "1800/1800 [==============================] - 0s 79us/step - loss: 0.3836 - accuracy: 0.8056 - val_loss: 0.3733 - val_accuracy: 0.8144\n",
      "Epoch 51/100\n",
      "1800/1800 [==============================] - 0s 88us/step - loss: 0.3813 - accuracy: 0.8072 - val_loss: 0.3707 - val_accuracy: 0.8178\n",
      "Epoch 52/100\n",
      "1800/1800 [==============================] - 0s 92us/step - loss: 0.3790 - accuracy: 0.8086 - val_loss: 0.3682 - val_accuracy: 0.8189\n",
      "Epoch 53/100\n",
      "1800/1800 [==============================] - 0s 84us/step - loss: 0.3768 - accuracy: 0.8094 - val_loss: 0.3659 - val_accuracy: 0.8200\n",
      "Epoch 54/100\n",
      "1800/1800 [==============================] - 0s 84us/step - loss: 0.3746 - accuracy: 0.8106 - val_loss: 0.3634 - val_accuracy: 0.8222\n",
      "Epoch 55/100\n",
      "1800/1800 [==============================] - 0s 91us/step - loss: 0.3725 - accuracy: 0.8125 - val_loss: 0.3612 - val_accuracy: 0.8267\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800/1800 [==============================] - 0s 97us/step - loss: 0.3704 - accuracy: 0.8131 - val_loss: 0.3590 - val_accuracy: 0.8278\n",
      "Epoch 57/100\n",
      "1800/1800 [==============================] - 0s 80us/step - loss: 0.3684 - accuracy: 0.8139 - val_loss: 0.3568 - val_accuracy: 0.8311\n",
      "Epoch 58/100\n",
      "1800/1800 [==============================] - 0s 70us/step - loss: 0.3664 - accuracy: 0.8156 - val_loss: 0.3545 - val_accuracy: 0.8322\n",
      "Epoch 59/100\n",
      "1800/1800 [==============================] - 0s 75us/step - loss: 0.3645 - accuracy: 0.8172 - val_loss: 0.3525 - val_accuracy: 0.8333\n",
      "Epoch 60/100\n",
      "1800/1800 [==============================] - 0s 88us/step - loss: 0.3626 - accuracy: 0.8186 - val_loss: 0.3503 - val_accuracy: 0.8344\n",
      "Epoch 61/100\n",
      "1800/1800 [==============================] - 0s 101us/step - loss: 0.3607 - accuracy: 0.8200 - val_loss: 0.3483 - val_accuracy: 0.8356\n",
      "Epoch 62/100\n",
      "1800/1800 [==============================] - 0s 89us/step - loss: 0.3589 - accuracy: 0.8214 - val_loss: 0.3463 - val_accuracy: 0.8378\n",
      "Epoch 63/100\n",
      "1800/1800 [==============================] - 0s 116us/step - loss: 0.3572 - accuracy: 0.8228 - val_loss: 0.3444 - val_accuracy: 0.8400\n",
      "Epoch 64/100\n",
      "1800/1800 [==============================] - 0s 93us/step - loss: 0.3555 - accuracy: 0.8236 - val_loss: 0.3424 - val_accuracy: 0.8411\n",
      "Epoch 65/100\n",
      "1800/1800 [==============================] - 0s 91us/step - loss: 0.3538 - accuracy: 0.8256 - val_loss: 0.3407 - val_accuracy: 0.8411\n",
      "Epoch 66/100\n",
      "1800/1800 [==============================] - 0s 95us/step - loss: 0.3522 - accuracy: 0.8264 - val_loss: 0.3386 - val_accuracy: 0.8456\n",
      "Epoch 67/100\n",
      "1800/1800 [==============================] - 0s 111us/step - loss: 0.3505 - accuracy: 0.8281 - val_loss: 0.3370 - val_accuracy: 0.8467\n",
      "Epoch 68/100\n",
      "1800/1800 [==============================] - 0s 87us/step - loss: 0.3490 - accuracy: 0.8294 - val_loss: 0.3353 - val_accuracy: 0.8489\n",
      "Epoch 69/100\n",
      "1800/1800 [==============================] - 0s 80us/step - loss: 0.3475 - accuracy: 0.8303 - val_loss: 0.3334 - val_accuracy: 0.8511\n",
      "Epoch 70/100\n",
      "1800/1800 [==============================] - 0s 71us/step - loss: 0.3460 - accuracy: 0.8319 - val_loss: 0.3317 - val_accuracy: 0.8533\n",
      "Epoch 71/100\n",
      "1800/1800 [==============================] - 0s 104us/step - loss: 0.3445 - accuracy: 0.8333 - val_loss: 0.3301 - val_accuracy: 0.8567\n",
      "Epoch 72/100\n",
      "1800/1800 [==============================] - 0s 91us/step - loss: 0.3431 - accuracy: 0.8339 - val_loss: 0.3285 - val_accuracy: 0.8589\n",
      "Epoch 73/100\n",
      "1800/1800 [==============================] - 0s 81us/step - loss: 0.3417 - accuracy: 0.8353 - val_loss: 0.3269 - val_accuracy: 0.8600\n",
      "Epoch 74/100\n",
      "1800/1800 [==============================] - 0s 86us/step - loss: 0.3403 - accuracy: 0.8369 - val_loss: 0.3255 - val_accuracy: 0.8611\n",
      "Epoch 75/100\n",
      "1800/1800 [==============================] - 0s 90us/step - loss: 0.3390 - accuracy: 0.8383 - val_loss: 0.3239 - val_accuracy: 0.8622\n",
      "Epoch 76/100\n",
      "1800/1800 [==============================] - 0s 98us/step - loss: 0.3377 - accuracy: 0.8389 - val_loss: 0.3221 - val_accuracy: 0.8622\n",
      "Epoch 77/100\n",
      "1800/1800 [==============================] - 0s 89us/step - loss: 0.3364 - accuracy: 0.8397 - val_loss: 0.3208 - val_accuracy: 0.8633\n",
      "Epoch 78/100\n",
      "1800/1800 [==============================] - 0s 88us/step - loss: 0.3352 - accuracy: 0.8400 - val_loss: 0.3194 - val_accuracy: 0.8633\n",
      "Epoch 79/100\n",
      "1800/1800 [==============================] - 0s 110us/step - loss: 0.3339 - accuracy: 0.8411 - val_loss: 0.3180 - val_accuracy: 0.8633\n",
      "Epoch 80/100\n",
      "1800/1800 [==============================] - 0s 89us/step - loss: 0.3328 - accuracy: 0.8425 - val_loss: 0.3165 - val_accuracy: 0.8633\n",
      "Epoch 81/100\n",
      "1800/1800 [==============================] - 0s 92us/step - loss: 0.3316 - accuracy: 0.8431 - val_loss: 0.3151 - val_accuracy: 0.8644\n",
      "Epoch 82/100\n",
      "1800/1800 [==============================] - 0s 86us/step - loss: 0.3306 - accuracy: 0.8444 - val_loss: 0.3140 - val_accuracy: 0.8644\n",
      "Epoch 83/100\n",
      "1800/1800 [==============================] - 0s 81us/step - loss: 0.3294 - accuracy: 0.8453 - val_loss: 0.3125 - val_accuracy: 0.8656\n",
      "Epoch 84/100\n",
      "1800/1800 [==============================] - 0s 81us/step - loss: 0.3283 - accuracy: 0.8461 - val_loss: 0.3111 - val_accuracy: 0.8667\n",
      "Epoch 85/100\n",
      "1800/1800 [==============================] - 0s 103us/step - loss: 0.3273 - accuracy: 0.8461 - val_loss: 0.3100 - val_accuracy: 0.8667\n",
      "Epoch 86/100\n",
      "1800/1800 [==============================] - 0s 91us/step - loss: 0.3263 - accuracy: 0.8467 - val_loss: 0.3086 - val_accuracy: 0.8678\n",
      "Epoch 87/100\n",
      "1800/1800 [==============================] - 0s 83us/step - loss: 0.3252 - accuracy: 0.8483 - val_loss: 0.3076 - val_accuracy: 0.8700\n",
      "Epoch 88/100\n",
      "1800/1800 [==============================] - 0s 87us/step - loss: 0.3243 - accuracy: 0.8489 - val_loss: 0.3066 - val_accuracy: 0.8700\n",
      "Epoch 89/100\n",
      "1800/1800 [==============================] - 0s 84us/step - loss: 0.3234 - accuracy: 0.8500 - val_loss: 0.3052 - val_accuracy: 0.8689\n",
      "Epoch 90/100\n",
      "1800/1800 [==============================] - 0s 76us/step - loss: 0.3224 - accuracy: 0.8506 - val_loss: 0.3042 - val_accuracy: 0.8689\n",
      "Epoch 91/100\n",
      "1800/1800 [==============================] - 0s 84us/step - loss: 0.3215 - accuracy: 0.8506 - val_loss: 0.3030 - val_accuracy: 0.8711\n",
      "Epoch 92/100\n",
      "1800/1800 [==============================] - 0s 85us/step - loss: 0.3206 - accuracy: 0.8511 - val_loss: 0.3020 - val_accuracy: 0.8711\n",
      "Epoch 93/100\n",
      "1800/1800 [==============================] - 0s 86us/step - loss: 0.3198 - accuracy: 0.8508 - val_loss: 0.3008 - val_accuracy: 0.8722\n",
      "Epoch 94/100\n",
      "1800/1800 [==============================] - 0s 74us/step - loss: 0.3190 - accuracy: 0.8514 - val_loss: 0.2998 - val_accuracy: 0.8733\n",
      "Epoch 95/100\n",
      "1800/1800 [==============================] - 0s 74us/step - loss: 0.3182 - accuracy: 0.8519 - val_loss: 0.2989 - val_accuracy: 0.8733\n",
      "Epoch 96/100\n",
      "1800/1800 [==============================] - 0s 78us/step - loss: 0.3173 - accuracy: 0.8533 - val_loss: 0.2978 - val_accuracy: 0.8756\n",
      "Epoch 97/100\n",
      "1800/1800 [==============================] - 0s 94us/step - loss: 0.3166 - accuracy: 0.8539 - val_loss: 0.2968 - val_accuracy: 0.8744\n",
      "Epoch 98/100\n",
      "1800/1800 [==============================] - 0s 81us/step - loss: 0.3159 - accuracy: 0.8525 - val_loss: 0.2958 - val_accuracy: 0.8744\n",
      "Epoch 99/100\n",
      "1800/1800 [==============================] - 0s 76us/step - loss: 0.3151 - accuracy: 0.8536 - val_loss: 0.2948 - val_accuracy: 0.8744\n",
      "Epoch 100/100\n",
      "1800/1800 [==============================] - 0s 90us/step - loss: 0.3144 - accuracy: 0.8550 - val_loss: 0.2940 - val_accuracy: 0.8756\n",
      "{'val_loss': [0.7670331954956054, 0.7433876744906107, 0.721224365764194, 0.7005574075380961, 0.6810125284724765, 0.6630020120408799, 0.646090612411499, 0.6300593201319377, 0.6150761347346836, 0.6014716386795044, 0.587997482087877, 0.5758162779278225, 0.5645175194740295, 0.5536130767398411, 0.5434706468052334, 0.5337123011218177, 0.5247960784700182, 0.5160448466406928, 0.5079818385177188, 0.5002882774670919, 0.4929565441608429, 0.48620861477322047, 0.47969874646928573, 0.4733898851606581, 0.4675445787111918, 0.46184391604529484, 0.45640806939866807, 0.4510152796904246, 0.44622443119684857, 0.4415587298075358, 0.43688316583633424, 0.4324358231491513, 0.42820367203818427, 0.42428918957710265, 0.42011968387497794, 0.4163794243335724, 0.412667093012068, 0.409321329858568, 0.4058745339181688, 0.40256289482116697, 0.3993831916650136, 0.39590432074334886, 0.3928410902288225, 0.3897632375028398, 0.38702447560098435, 0.38409974588288204, 0.3811757998996311, 0.3784134221076965, 0.3758144394556681, 0.3732679818736182, 0.37067153294881183, 0.3682086043887668, 0.36588885691430834, 0.36337829258706833, 0.36124721275435556, 0.35901966293652854, 0.35680759880277846, 0.3545240416791704, 0.35246549752023487, 0.35030460980203415, 0.34825205206871035, 0.34632280707359314, 0.3443628986676534, 0.34239402969678245, 0.34071927163336013, 0.3386242271794213, 0.33703795512517293, 0.33531939347585044, 0.33343991756439206, 0.33174097816149395, 0.33013596177101134, 0.3284646591875288, 0.32685467110739813, 0.3254520054658254, 0.3238632419374254, 0.3221495615111457, 0.32084352122412785, 0.31940512564447193, 0.31797221740086873, 0.3164982619550493, 0.3150959073172675, 0.31396843274434405, 0.31251484870910645, 0.3111061594221327, 0.30997040801578096, 0.3086221220758226, 0.3076020095083449, 0.3065876367357042, 0.3052051395840115, 0.3041924177275764, 0.30296551757388646, 0.30198061108589175, 0.30077457229296367, 0.2998289042048984, 0.2988642595873939, 0.29775046586990356, 0.29676922374301484, 0.2957945211728414, 0.29484296758969625, 0.2940015807416704], 'val_accuracy': [0.4677777886390686, 0.47333332896232605, 0.49444442987442017, 0.504444420337677, 0.5155555605888367, 0.5277777910232544, 0.5433333516120911, 0.5577777624130249, 0.5788888931274414, 0.6000000238418579, 0.6144444346427917, 0.6299999952316284, 0.6411111354827881, 0.6499999761581421, 0.6588888764381409, 0.6777777671813965, 0.6877777576446533, 0.6922222375869751, 0.699999988079071, 0.70333331823349, 0.7155555486679077, 0.7188888788223267, 0.7277777791023254, 0.7333333492279053, 0.7400000095367432, 0.7477777600288391, 0.7511110901832581, 0.753333330154419, 0.7611111402511597, 0.7633333206176758, 0.7655555605888367, 0.7688888907432556, 0.7711111307144165, 0.7722222208976746, 0.7755555510520935, 0.7811111211776733, 0.7855555415153503, 0.7877777814865112, 0.7888888716697693, 0.7922222018241882, 0.7944444417953491, 0.7988888621330261, 0.8022222518920898, 0.804444432258606, 0.8055555820465088, 0.8077777624130249, 0.8088889122009277, 0.8122222423553467, 0.8133333325386047, 0.8144444227218628, 0.8177777528762817, 0.8188889026641846, 0.8199999928474426, 0.8222222328186035, 0.8266666531562805, 0.8277778029441833, 0.8311111330986023, 0.8322222232818604, 0.8333333134651184, 0.8344444632530212, 0.8355555534362793, 0.8377777934074402, 0.8399999737739563, 0.8411111235618591, 0.8411111235618591, 0.8455555438995361, 0.846666693687439, 0.8488888740539551, 0.851111114025116, 0.8533333539962769, 0.8566666841506958, 0.8588888645172119, 0.8600000143051147, 0.8611111044883728, 0.8622221946716309, 0.8622221946716309, 0.8633333444595337, 0.8633333444595337, 0.8633333444595337, 0.8633333444595337, 0.8644444346427917, 0.8644444346427917, 0.8655555844306946, 0.8666666746139526, 0.8666666746139526, 0.8677777647972107, 0.8700000047683716, 0.8700000047683716, 0.8688889145851135, 0.8688889145851135, 0.8711110949516296, 0.8711110949516296, 0.8722222447395325, 0.8733333349227905, 0.8733333349227905, 0.8755555748939514, 0.8744444251060486, 0.8744444251060486, 0.8744444251060486, 0.8755555748939514], 'loss': [0.7859174903233846, 0.760781479941474, 0.7376135804918077, 0.7157914842499628, 0.6954787344402737, 0.6763795402314928, 0.6584475109312269, 0.6418215396669176, 0.6263509970241122, 0.6118100966347588, 0.5982058350245157, 0.5854131115807427, 0.5734943479961819, 0.562351938088735, 0.5518222946590847, 0.541997889942593, 0.5327421238687303, 0.5239090598954095, 0.5155699866347843, 0.5077683533562555, 0.5004665676752726, 0.4935657776726617, 0.4870164452658759, 0.4807799855868022, 0.47485028160942927, 0.46912263406647575, 0.46376015490955774, 0.4586833482318454, 0.453741192817688, 0.4490406878789266, 0.4445552757051256, 0.44017659491962857, 0.4360053335295783, 0.4320480991072125, 0.4282233455446031, 0.4245173446337382, 0.42093482573827107, 0.41750703308317394, 0.41418431613180373, 0.4109564456012514, 0.40785567018720836, 0.404833017985026, 0.4018872752454546, 0.3990681963496738, 0.39634356843100654, 0.39366168803638885, 0.3910307689507802, 0.3884643395741781, 0.38601838880115086, 0.3835924176375071, 0.38126177165243363, 0.37900220500098336, 0.3767809886402554, 0.3746130139297909, 0.37245217190848456, 0.3704127038849725, 0.3683934375974867, 0.3664043731159634, 0.3644912013080385, 0.36262543678283693, 0.36073327422142026, 0.3589250832133823, 0.3571735909250047, 0.3554571204715305, 0.35376936515172325, 0.352174993885888, 0.35052158302730985, 0.3490175766415066, 0.3474859558211433, 0.3460314738750458, 0.3445128558741675, 0.34308963735898335, 0.34170519749323525, 0.3403446594874064, 0.3390295632680257, 0.33768614689509074, 0.3364240943060981, 0.3351595977942149, 0.3339449856016371, 0.3327814649211036, 0.3316157615184784, 0.33055979477034675, 0.3293653938505385, 0.3283276422818502, 0.3272790100177129, 0.3262512469291687, 0.3252484215630425, 0.32430133508311376, 0.32336108340157405, 0.3224440105756124, 0.32154857211642796, 0.3206437377134959, 0.31978286027908326, 0.3189597521887885, 0.31816251860724554, 0.3173429576555888, 0.3165828479660882, 0.3158736213710573, 0.31514939970440337, 0.3144282003243764], 'accuracy': [0.4422222, 0.45777777, 0.475, 0.4913889, 0.50416666, 0.52055556, 0.53805554, 0.5555556, 0.5733333, 0.58944446, 0.60388887, 0.61333334, 0.62333333, 0.63805556, 0.6488889, 0.6591667, 0.66944444, 0.68222225, 0.6905556, 0.7002778, 0.7063889, 0.7113889, 0.72, 0.7263889, 0.73444444, 0.74, 0.7438889, 0.7463889, 0.74972224, 0.7538889, 0.75972223, 0.7619445, 0.7647222, 0.7675, 0.77, 0.7725, 0.7752778, 0.77694446, 0.77916664, 0.7825, 0.78555554, 0.78694445, 0.79083335, 0.7922222, 0.79444444, 0.79833335, 0.8005555, 0.80222225, 0.8041667, 0.8055556, 0.80722225, 0.8086111, 0.8094444, 0.8105556, 0.8125, 0.8130556, 0.8138889, 0.8155556, 0.81722224, 0.8186111, 0.82, 0.8213889, 0.82277775, 0.82361114, 0.82555556, 0.8263889, 0.82805556, 0.82944447, 0.8302778, 0.83194447, 0.8333333, 0.8338889, 0.8352778, 0.83694446, 0.8383333, 0.8388889, 0.8397222, 0.84, 0.8411111, 0.8425, 0.84305555, 0.84444445, 0.8452778, 0.8461111, 0.8461111, 0.8466667, 0.84833336, 0.8488889, 0.85, 0.85055554, 0.85055554, 0.8511111, 0.85083336, 0.8513889, 0.85194445, 0.85333335, 0.85388887, 0.8525, 0.8536111, 0.855]}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# prepare the data\n",
    "X= np.array(X)\n",
    "Y= np.array(Y)\n",
    "from keras.utils import to_categorical\n",
    "split = int(0.8*X.shape[0])\n",
    "Xtrain=X[:split]\n",
    "Xval= X[split:]\n",
    "\n",
    "Ytrain= Y[:split]\n",
    "Yval= Y[split:]\n",
    "Ytrain= to_categorical(Ytrain)\n",
    "Yval= to_categorical(Yval)\n",
    "h= model.fit(Xtrain, Ytrain, epochs = 100 , validation_data= (Xval, Yval))\n",
    "hist = h.history\n",
    "print(hist)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(hist[\"val_loss\"],label= \"validation loss\")\n",
    "plt.plot(hist[\"loss\"],label= \" loss\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750, 2) (750, 1)\n"
     ]
    }
   ],
   "source": [
    "Xtest= pd.read_csv(\"./datasets/NeuralNetwork1_X_Test.csv\")\n",
    "Ytest = model.predict(Xtest)\n",
    "print(Xtest.shape, Ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytest= np.array(Ytest)\n",
    "Ytest[Ytest>=0.5]= int(1)\n",
    "Ytest[Ytest<0.5]= int(0 )\n",
    "Ytest= pd.DataFrame(Ytest)\n",
    "Ytest.columns= [\"label\"]\n",
    "Ytest.to_csv(\"./datasets/result_NeuralNetwork1.csv\", header= True, index= False)\n",
    "# 84% using neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vindyanchal\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\vindyanchal\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8675555555555555"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X,Y)\n",
    "lr.score(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
