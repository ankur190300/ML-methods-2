{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import word2vec embeddings \n",
    "- word2vec embeddings are already pre-installed in the system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = KeyedVectors.load_word2vec_format(\"../GoogleNews-vectors-negative300.bin/GoogleNews-vectors-negative300.bin\", binary= True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_words= pd.read_csv(\"./datasets/odd_one_out_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word1</th>\n",
       "      <th>Word2</th>\n",
       "      <th>Word3</th>\n",
       "      <th>Word4</th>\n",
       "      <th>Word5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>elephant</td>\n",
       "      <td>lion</td>\n",
       "      <td>tiger</td>\n",
       "      <td>goat</td>\n",
       "      <td>snake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>man</td>\n",
       "      <td>policeman</td>\n",
       "      <td>fireman</td>\n",
       "      <td>teacher</td>\n",
       "      <td>postman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>plane</td>\n",
       "      <td>bird</td>\n",
       "      <td>rocket</td>\n",
       "      <td>balloon</td>\n",
       "      <td>cat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>onion</td>\n",
       "      <td>celery</td>\n",
       "      <td>lettuce</td>\n",
       "      <td>pineapple</td>\n",
       "      <td>potato</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>India</td>\n",
       "      <td>football</td>\n",
       "      <td>hockey</td>\n",
       "      <td>cricket</td>\n",
       "      <td>swimming</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Word1      Word2    Word3      Word4     Word5\n",
       "0  elephant       lion    tiger       goat     snake\n",
       "1       man  policeman  fireman    teacher   postman\n",
       "2     plane       bird   rocket    balloon       cat\n",
       "3     onion     celery  lettuce  pineapple    potato\n",
       "4     India   football   hockey    cricket  swimming"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_words.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the odd_one_out function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def odd_one_out(words):\n",
    "    odd_one_out= None ;\n",
    "    all_vectors= [word_vectors[w] for w in words]\n",
    "    mean_vector = np.mean(all_vectors, axis =0 )\n",
    "    min_similarity = 1.0;\n",
    "    for w in words:\n",
    "        sim = cosine_similarity([mean_vector] , [word_vectors[w]])\n",
    "        #print(\"for the word %s the similarity is %.2f \"%(w, sim))\n",
    "        if sim < min_similarity:\n",
    "            \n",
    "            min_similarity = sim \n",
    "            odd_one_out = w;\n",
    "    return odd_one_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "np_test_words = np.array(test_words)\n",
    "result= []\n",
    "print(np_test_words.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(np_test_words.shape[0]):\n",
    "    result.append(odd_one_out(np_test_words[i]))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['snake', 'teacher', 'cat', 'pineapple', 'India', 'is', 'was', 'Australia', 'Money', 'think', 'ship', 'Rome', 'Pool', 'Egypt', 'mouse', 'helmet', 'Universe', 'Kill', 'Club', 'Sun']\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0\n",
      "0       snake\n",
      "1     teacher\n",
      "2         cat\n",
      "3   pineapple\n",
      "4       India\n",
      "5          is\n",
      "6         was\n",
      "7   Australia\n",
      "8       Money\n",
      "9       think\n",
      "10       ship\n",
      "11       Rome\n",
      "12       Pool\n",
      "13      Egypt\n",
      "14      mouse\n",
      "15     helmet\n",
      "16   Universe\n",
      "17       Kill\n",
      "18       Club\n",
      "19        Sun\n"
     ]
    }
   ],
   "source": [
    "output= pd.DataFrame(result)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv(\"./datasets/odd_one_out_output.csv\", header= [\"OddOne\"], index= False) # 85% accuracy\n",
    "# predicted kill,helmet, teacher instead of kidnap, shirt , man "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using glove6b-50d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"txtfiles/glove.6B.50d.txt\", encoding=\"UTF-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_index = {}\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs= np.array(values[1:], dtype='float')\n",
    "    embedding_index[word]= coefs\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def odd_one_out2(words):\n",
    "    odd_one_out= None \n",
    "    itr = 0 \n",
    "    all_vectors = []\n",
    "    word= []\n",
    "    for w in words:\n",
    "        try:\n",
    "            all_vectors.append(embedding_index[w]) \n",
    "            word.append(w)\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    mean_vector = np.mean(all_vectors, axis =0 )\n",
    "    min_similarity = 1.0;\n",
    "    for w in word:\n",
    "        sim = cosine_similarity([mean_vector] , [embedding_index[w]])\n",
    "        print(\"for the word %s the similarity is %.2f \"%(w, sim))\n",
    "        if sim < min_similarity:\n",
    "            \n",
    "            min_similarity = sim \n",
    "            odd_one_out = w;\n",
    "    return odd_one_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for the word apple the similarity is 0.81 \n",
      "for the word orange the similarity is 0.81 \n",
      "for the word party the similarity is 0.52 \n",
      "for the word juice the similarity is 0.85 \n",
      "for the word guava the similarity is 0.69 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'party'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input1= [\"apple\" ,\"orange\", \"party\", \"juice\", \"guava\"];\n",
    "odd_one_out2(input1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for the word elephant the similarity is 0.90 \n",
      "for the word lion the similarity is 0.82 \n",
      "for the word tiger the similarity is 0.78 \n",
      "for the word goat the similarity is 0.79 \n",
      "for the word snake the similarity is 0.83 \n",
      "for the word man the similarity is 0.86 \n",
      "for the word policeman the similarity is 0.82 \n",
      "for the word fireman the similarity is 0.66 \n",
      "for the word teacher the similarity is 0.78 \n",
      "for the word postman the similarity is 0.54 \n",
      "for the word plane the similarity is 0.81 \n",
      "for the word bird the similarity is 0.69 \n",
      "for the word rocket the similarity is 0.73 \n",
      "for the word balloon the similarity is 0.77 \n",
      "for the word cat the similarity is 0.71 \n",
      "for the word onion the similarity is 0.90 \n",
      "for the word celery the similarity is 0.90 \n",
      "for the word lettuce the similarity is 0.89 \n",
      "for the word pineapple the similarity is 0.83 \n",
      "for the word potato the similarity is 0.85 \n",
      "for the word football the similarity is 0.92 \n",
      "for the word hockey the similarity is 0.88 \n",
      "for the word cricket the similarity is 0.82 \n",
      "for the word swimming the similarity is 0.75 \n",
      "for the word who the similarity is 0.84 \n",
      "for the word why the similarity is 0.92 \n",
      "for the word what the similarity is 0.93 \n",
      "for the word where the similarity is 0.87 \n",
      "for the word is the similarity is 0.87 \n",
      "for the word on the similarity is 0.96 \n",
      "for the word in the similarity is 0.94 \n",
      "for the word over the similarity is 0.92 \n",
      "for the word their the similarity is 0.87 \n",
      "for the word was the similarity is 0.86 \n",
      "for the word eat the similarity is 0.86 \n",
      "for the word sleep the similarity is 0.77 \n",
      "for the word drink the similarity is 0.81 \n",
      "for the word think the similarity is 0.77 \n",
      "for the word dance the similarity is 0.67 \n",
      "for the word car the similarity is 0.90 \n",
      "for the word scooter the similarity is 0.67 \n",
      "for the word bike the similarity is 0.89 \n",
      "for the word bicycle the similarity is 0.91 \n",
      "for the word ship the similarity is 0.65 \n",
      "for the word fox the similarity is 0.72 \n",
      "for the word wolf the similarity is 0.83 \n",
      "for the word jackal the similarity is 0.66 \n",
      "for the word mouse the similarity is 0.78 \n",
      "for the word panther the similarity is 0.75 \n",
      "for the word veil the similarity is 0.72 \n",
      "for the word turban the similarity is 0.79 \n",
      "for the word helmet the similarity is 0.80 \n",
      "for the word shirt the similarity is 0.90 \n",
      "for the word hat the similarity is 0.84 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vindyanchal\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\vindyanchal\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\vindyanchal\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\vindyanchal\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\vindyanchal\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\vindyanchal\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "result2=[]\n",
    "for i in range(np_test_words.shape[0]):\n",
    "    result2.append(odd_one_out2(np_test_words[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tiger', 'postman', 'bird', 'pineapple', 'swimming', 'who', 'was', None, None, 'dance', 'ship', None, None, None, 'jackal', 'veil', None, None, None, None]\n"
     ]
    }
   ],
   "source": [
    "print(result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['snake', 'teacher', 'cat', 'pineapple', 'India', 'is', 'was', 'Australia', 'Money', 'think', 'ship', 'Rome', 'Pool', 'Egypt', 'mouse', 'helmet', 'Universe', 'Kill', 'Club', 'Sun']\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as we can see using glove is not feasable as all google word_to_vec is vastly superior in terms of \n",
    "#number of words present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
